{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Sea inverse_input.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfAhXu_6xMGA"
      },
      "source": [
        "# **Dataset Creating**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru_JS0A_-3Gu"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import spacy\n",
        "import torchtext\n",
        "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
        "import torch.nn.functional as F\n",
        "from random import seed\n",
        "from random import randint\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random \n",
        "\n",
        "\n",
        "seed(1)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wFAU2c0K_xU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e77e4e2-c9b9-430b-f5ea-64f35f263325"
      },
      "source": [
        "#Creat a data set\n",
        "Pool_data = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
        "#Create function returning the random word and its inverse.\n",
        "def RandomWord(data, length):\n",
        "  word = ''\n",
        "  for i in range(length):\n",
        "    word = word + Pool_data[randint(0,len(Pool_data)-1)]\n",
        "  return word, word[::-1]\n",
        "\n",
        "#Make train and test set\n",
        "keep_train = []\n",
        "for i in range(2,30):\n",
        "  if i>15:\n",
        "    for k in range(250):\n",
        "      src, tar = RandomWord(Pool_data, i)\n",
        "      keep_train.append([src, tar])\n",
        "  else:\n",
        "    for k in range(500):\n",
        "      src, tar = RandomWord(Pool_data, i)\n",
        "      keep_train.append([src, tar])\n",
        "train = pd.DataFrame(np.array(keep_train),\n",
        "                  columns=['source', 'target'])\n",
        "print(train.shape)\n",
        "\n",
        "keep_test = []\n",
        "for j in range(80):\n",
        "  for i in range(2,30):\n",
        "      src, tar = RandomWord(Pool_data, i)\n",
        "      keep_test.append([src, tar])\n",
        "test = pd.DataFrame(np.array(keep_test),\n",
        "                  columns=['source', 'target'])\n",
        "print(test.shape)\n",
        "\n",
        "keep_val = []\n",
        "for j in range(60):\n",
        "  for i in range(randint(2,30)):\n",
        "      src, tar = RandomWord(Pool_data, i)\n",
        "      keep_val.append([src, tar])\n",
        "val = pd.DataFrame(np.array(keep_val),\n",
        "                  columns=['source', 'target'])\n",
        "print(val.shape)\n",
        "\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)\n",
        "val.to_csv(\"val.csv\", index=False)\n"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10500, 2)\n",
            "(2240, 2)\n",
            "(882, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9CjUPLsSKbk"
      },
      "source": [
        "def token_char(text):\n",
        "  token = []\n",
        "  for char in text:\n",
        "    token.append(char)\n",
        "  return token\n",
        "\n",
        "SRC = Field(tokenize=token_char,\n",
        "            init_token = '<sos>',\n",
        "            eos_token='<eos>')\n",
        "TRG = Field(tokenize=token_char,\n",
        "            init_token = '<sos>',\n",
        "            eos_token='<eos>')\n",
        "\n",
        "\n",
        "\n",
        "fields = {\"source\": (\"src\", SRC), \"target\" : (\"trg\",TRG)}\n",
        "\n",
        "train_data, valid_data, test_data = TabularDataset.splits(\n",
        "    path=\"/content/\", train=\"train.csv\", validation=\"val.csv\", test=\"test.csv\", format=\"csv\", fields=fields\n",
        ")\n",
        "\n",
        "SRC.build_vocab(train_data,  min_freq=1)\n",
        "TRG.build_vocab(train_data,  min_freq=1)"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCNX4eUcUrwk",
        "outputId": "f0f76215-2674-44bd-8bf5-87fd18571ae1"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test_data.examples)}\")\n",
        "\n",
        "print(test_data[2].__dict__.keys())\n",
        "print(test_data[2].__dict__.values())"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 10500\n",
            "Number of validation examples: 882\n",
            "Number of testing examples: 2240\n",
            "dict_keys(['src', 'trg'])\n",
            "dict_values([['s', 'r', 'v', 'i'], ['i', 'v', 'r', 's']])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev4TAi3xVJg9"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 128\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    sort_within_batch = True,\n",
        "    sort_key = lambda x: len(x.src),\n",
        "    device = device)"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmVoyDOfWEoS"
      },
      "source": [
        "# **MODEL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FY_B3kV7Ttjg"
      },
      "source": [
        "**ENCONDER** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX6O-qjkTm5i"
      },
      "source": [
        "class encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, embedded_size):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size  \n",
        "        self.embedded_size = embedded_size\n",
        "\n",
        "        self.embed = nn.Embedding(input_size, self.embedded_size)\n",
        "        self.gru = nn.GRU(self.embedded_size, self.hidden_size)\n",
        "\n",
        "    def forward(self, source, hidden):\n",
        "\n",
        "        emb = self.embed(source).unsqueeze(0)\n",
        "        outputs, hidden = self.gru(emb,hidden)\n",
        "\n",
        "        return hidden\n"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEM_6wiJVX5r"
      },
      "source": [
        "**DECODER** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOeHBKaPVawy"
      },
      "source": [
        "class decoder(nn.Module):\n",
        "    def __init__(self, output_size, hidden_size, embedded_size):\n",
        "        super().__init__()\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedded_size = embedded_size\n",
        "\n",
        "        self.embed = nn.Embedding(output_size, self.embedded_size)\n",
        "        self.gru = nn.GRU(self.embedded_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "        self.soft = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, source, hidden):\n",
        "        \n",
        "        source = source.unsqueeze(0)\n",
        "        emb = self.embed(source)\n",
        "        output, hidden = self.gru(emb, hidden)\n",
        "        pred = self.soft(self.out(output[0]))\n",
        "\n",
        "        return pred, hidden\n"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDOKlCFnbJe0"
      },
      "source": [
        "**Sequence to Sequence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W524q0DCbNjp"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "   def __init__(self, encoder, decoder, device):\n",
        "       super(Seq2Seq, self).__init__()\n",
        "\n",
        "       self.encoder = encoder\n",
        "       self.decoder = decoder\n",
        "       self.device = device\n",
        "   def forward(self, source, target):\n",
        "\n",
        "       input_length = source.size(0)\n",
        "       batch_size = target.shape[1] \n",
        "       target_length = target.shape[0]\n",
        "       vocab_size = self.decoder.output_size\n",
        "       \n",
        "\n",
        "       feedHidden = torch.zeros(1, batch_size, 256).to(device)\n",
        "       for i in range(input_length):\n",
        "          hidden = self.encoder(source[i], feedHidden)\n",
        "          feedHidden = hidden\n",
        "          \n",
        "\n",
        "       outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device)\n",
        "       \n",
        "       decode_input = target[0,:]\n",
        "\n",
        "       for i in range(1, target_length):\n",
        "        \n",
        "        output, hidden= self.decoder(decode_input, feedHidden)\n",
        "        outputs[i] = output\n",
        "        top1 = output.argmax(1) \n",
        "        tf = random.random() < 0.5\n",
        "        decode_input = target[i] if tf else top1\n",
        "        feedHidden = hidden\n",
        "\n",
        "       return outputs"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvQfe1Yw7M1J"
      },
      "source": [
        "# **Initialize model and its parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUR8LQNVxOES",
        "outputId": "7483d59e-f54e-4d11-d6f0-c745d6412c4a"
      },
      "source": [
        "Input_size = len(SRC.vocab)\n",
        "Output_size = len(TRG.vocab)\n",
        "Embbed_size = 256\n",
        "Hidden_size = 256\n",
        "\n",
        "Encoder = encoder(Input_size, Hidden_size, Embbed_size)\n",
        "Decoder = decoder(Output_size, Hidden_size, Embbed_size)\n",
        "\n",
        "Model = Seq2Seq(Encoder, Decoder, device).to(device)\n",
        "print(Model)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seq2Seq(\n",
            "  (encoder): encoder(\n",
            "    (embed): Embedding(30, 256)\n",
            "    (gru): GRU(256, 256)\n",
            "  )\n",
            "  (decoder): decoder(\n",
            "    (embed): Embedding(30, 256)\n",
            "    (gru): GRU(256, 256)\n",
            "    (out): Linear(in_features=256, out_features=30, bias=True)\n",
            "    (soft): LogSoftmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8opTCaHQyC3N",
        "outputId": "f9623075-159c-46c2-f565-d77e3438c9d1"
      },
      "source": [
        "LearningRate = 1e-3\n",
        "Optimizer = optim.Adam(Model.parameters(), lr=LearningRate)\n",
        "\n",
        "TRG_IDX = TRG.vocab.stoi['<pad>']\n",
        "print(TRG_IDX)\n",
        "Crit = nn.CrossEntropyLoss(ignore_index=TRG_IDX)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sRSYTP7WwpM"
      },
      "source": [
        "# **Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6N5A_PEyxmH",
        "outputId": "e0c65bea-a758-4aa3-d55a-66c8b911d115"
      },
      "source": [
        "NumEpoch = 50\n",
        "EpochLoss = 0\n",
        "Model.train(True)\n",
        "\n",
        "for epoch in range(0, NumEpoch):\n",
        "\n",
        "  print('Epoch {}/{}' .format((epoch+1),(NumEpoch)))\n",
        "\n",
        "  for num, batch in enumerate(train_iterator):\n",
        "    source = (batch.src).to(device)\n",
        "    target = (batch.trg).to(device)\n",
        "    \n",
        "    Output = Model(source, target)\n",
        "    #จัด Output ใหม่ ไม่เอา <sos> จะได้ไปเข้า CrossEntropy ได้\n",
        "    Output = Output[1:].reshape(-1, Output.shape[2]) #กลายเป็น [(1-ความยาวsource)*batch_size, vocab_size]\n",
        "    Target = target[1:].view(-1)\n",
        " \n",
        "    Optimizer.zero_grad()\n",
        "    Loss = Crit(Output, Target)\n",
        "    Loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(Model.parameters(), max_norm=1)\n",
        "    Optimizer.step()\n",
        "    EpochLoss += Loss.item()\n",
        "    \n",
        "  print('Epoch Loss: {:.3f}' .format(Loss))\n",
        "  print()"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "Epoch Loss: 2.916\n",
            "\n",
            "Epoch 2/50\n",
            "Epoch Loss: 1.928\n",
            "\n",
            "Epoch 3/50\n",
            "Epoch Loss: 0.152\n",
            "\n",
            "Epoch 4/50\n",
            "Epoch Loss: 2.280\n",
            "\n",
            "Epoch 5/50\n",
            "Epoch Loss: 1.139\n",
            "\n",
            "Epoch 6/50\n",
            "Epoch Loss: 0.421\n",
            "\n",
            "Epoch 7/50\n",
            "Epoch Loss: 0.692\n",
            "\n",
            "Epoch 8/50\n",
            "Epoch Loss: 1.249\n",
            "\n",
            "Epoch 9/50\n",
            "Epoch Loss: 0.649\n",
            "\n",
            "Epoch 10/50\n",
            "Epoch Loss: 1.140\n",
            "\n",
            "Epoch 11/50\n",
            "Epoch Loss: 0.103\n",
            "\n",
            "Epoch 12/50\n",
            "Epoch Loss: 1.008\n",
            "\n",
            "Epoch 13/50\n",
            "Epoch Loss: 1.233\n",
            "\n",
            "Epoch 14/50\n",
            "Epoch Loss: 1.162\n",
            "\n",
            "Epoch 15/50\n",
            "Epoch Loss: 0.015\n",
            "\n",
            "Epoch 16/50\n",
            "Epoch Loss: 1.997\n",
            "\n",
            "Epoch 17/50\n",
            "Epoch Loss: 1.009\n",
            "\n",
            "Epoch 18/50\n",
            "Epoch Loss: 0.008\n",
            "\n",
            "Epoch 19/50\n",
            "Epoch Loss: 0.899\n",
            "\n",
            "Epoch 20/50\n",
            "Epoch Loss: 0.890\n",
            "\n",
            "Epoch 21/50\n",
            "Epoch Loss: 0.428\n",
            "\n",
            "Epoch 22/50\n",
            "Epoch Loss: 0.262\n",
            "\n",
            "Epoch 23/50\n",
            "Epoch Loss: 0.628\n",
            "\n",
            "Epoch 24/50\n",
            "Epoch Loss: 1.710\n",
            "\n",
            "Epoch 25/50\n",
            "Epoch Loss: 2.173\n",
            "\n",
            "Epoch 26/50\n",
            "Epoch Loss: 1.081\n",
            "\n",
            "Epoch 27/50\n",
            "Epoch Loss: 0.036\n",
            "\n",
            "Epoch 28/50\n",
            "Epoch Loss: 0.005\n",
            "\n",
            "Epoch 29/50\n",
            "Epoch Loss: 0.009\n",
            "\n",
            "Epoch 30/50\n",
            "Epoch Loss: 0.308\n",
            "\n",
            "Epoch 31/50\n",
            "Epoch Loss: 1.846\n",
            "\n",
            "Epoch 32/50\n",
            "Epoch Loss: 0.216\n",
            "\n",
            "Epoch 33/50\n",
            "Epoch Loss: 0.001\n",
            "\n",
            "Epoch 34/50\n",
            "Epoch Loss: 0.062\n",
            "\n",
            "Epoch 35/50\n",
            "Epoch Loss: 0.108\n",
            "\n",
            "Epoch 36/50\n",
            "Epoch Loss: 1.179\n",
            "\n",
            "Epoch 37/50\n",
            "Epoch Loss: 0.435\n",
            "\n",
            "Epoch 38/50\n",
            "Epoch Loss: 0.290\n",
            "\n",
            "Epoch 39/50\n",
            "Epoch Loss: 0.663\n",
            "\n",
            "Epoch 40/50\n",
            "Epoch Loss: 1.591\n",
            "\n",
            "Epoch 41/50\n",
            "Epoch Loss: 1.918\n",
            "\n",
            "Epoch 42/50\n",
            "Epoch Loss: 0.300\n",
            "\n",
            "Epoch 43/50\n",
            "Epoch Loss: 0.642\n",
            "\n",
            "Epoch 44/50\n",
            "Epoch Loss: 0.002\n",
            "\n",
            "Epoch 45/50\n",
            "Epoch Loss: 0.467\n",
            "\n",
            "Epoch 46/50\n",
            "Epoch Loss: 0.214\n",
            "\n",
            "Epoch 47/50\n",
            "Epoch Loss: 0.097\n",
            "\n",
            "Epoch 48/50\n",
            "Epoch Loss: 0.009\n",
            "\n",
            "Epoch 49/50\n",
            "Epoch Loss: 0.234\n",
            "\n",
            "Epoch 50/50\n",
            "Epoch Loss: 1.083\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txiw2Tg5mf5R"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yOU66XvJ7Cy"
      },
      "source": [
        "# **Prediction Peeking**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDoVvwouKBXZ",
        "outputId": "9da25cf7-1ded-465f-d840-b583e70bec1e"
      },
      "source": [
        "def convert(model, words, normal, inverse, device):\n",
        "  tokens = [token for token in token_char(words)]\n",
        "  tokens.insert(0, SRC.init_token)\n",
        "  \n",
        "  tokens.append(TRG.eos_token)\n",
        "  text_to_indices = [SRC.vocab.stoi[token] for token in tokens]\n",
        "  sentence_tensor = torch.LongTensor(text_to_indices).to(device)\n",
        "\n",
        "\n",
        "  feedHidden = torch.zeros(1, 1, 256).to(device)\n",
        "  for i in range(0, len(sentence_tensor)-1):\n",
        "    hidden = Model.encoder(sentence_tensor[i].unsqueeze(0), feedHidden)\n",
        "    feedHidden = hidden\n",
        "\n",
        "  outputs = sentence_tensor[0].unsqueeze(0)\n",
        "\n",
        "  Pred = []\n",
        "  for i in range(0, len(sentence_tensor)-1):\n",
        "    output, hidden = Model.decoder(outputs, feedHidden)\n",
        "    top1 = output.argmax(1)\n",
        "    Pred.append(top1.item())\n",
        "    outputs = top1\n",
        "    feedHidden = hidden\n",
        "\n",
        "\n",
        "  translated_sentence = [SRC.vocab.itos[idx] for idx in Pred]\n",
        "  return translated_sentence[:-1] #เอา EOS ออก\n",
        "\n",
        "words = \"abcd\"\n",
        "words_predicted = convert(Model, words, SRC, TRG, device)\n",
        "print('Input word : ', words)\n",
        "print('Predicted word : ', words_predicted)\n",
        "print()\n",
        "words = \"com\"\n",
        "words_predicted = convert(Model, words, SRC, TRG, device)\n",
        "print('Input word : ', words)\n",
        "print('Predicted word : ', words_predicted)\n",
        "print()\n",
        "words = \"world\"\n",
        "words_predicted = convert(Model, words, SRC, TRG, device)\n",
        "print('Input word : ', words)\n",
        "print('Predicted word : ', words_predicted)\n",
        "print()\n",
        "\n",
        "words = \"thank\"\n",
        "words_predicted = convert(Model, words, SRC, TRG, device)\n",
        "print('Input word : ', words)\n",
        "print('Predicted word : ', words_predicted)"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word :  abcd\n",
            "Predicted word :  ['d', 'c', 'b', 'a']\n",
            "\n",
            "Input word :  com\n",
            "Predicted word :  ['m', 'o', 'c']\n",
            "\n",
            "Input word :  world\n",
            "Predicted word :  ['d', 'l', 'r', 'o', 'w']\n",
            "\n",
            "Input word :  thank\n",
            "Predicted word :  ['k', 'n', 'a', 'h', 't']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHLAes4DIqyD"
      },
      "source": [
        "# **Model Evalutaion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVdged47Itjz",
        "outputId": "aeec67f6-c21d-4427-bd80-08b8c90aa8bf"
      },
      "source": [
        "Model.eval()\n",
        "EpochLoss_eval = 0\n",
        "Loss = 0\n",
        "with torch.no_grad():\n",
        "  for num, batch in enumerate(test_iterator):\n",
        "    source = batch.src\n",
        "    target = batch.trg\n",
        "    Output = Model(source, target)\n",
        "\n",
        "\n",
        "    #จัด Output ใหม่ ไม่เอา <sos> จะได้ไปเข้า CrossEntropy ได้\n",
        "    Output = Output[1:].reshape(-1, Output.shape[2]) #กลายเป็น [(1-ความยาวsource)*batch_size, vocab_size]\n",
        "    Target = target[1:].view(-1)\n",
        "\n",
        "\n",
        "    Loss = Crit(Output, Target)\n",
        "    \n",
        "    EpochLoss_eval += Loss.item()\n",
        "  print('Test Loss: ', EpochLoss_eval/num)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss:  1.0577567942057025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJFnfjsaYP5H",
        "outputId": "6cc3c51f-ee3b-4fb2-dc0f-cf5d50e5ef7b"
      },
      "source": [
        "#BLEU SCORE\n",
        "from torchtext.data.metrics import bleu_score\n",
        "Target = []\n",
        "Output = []\n",
        "\n",
        "for data in test_data[:20]:\n",
        "  source = vars(data)[\"src\"]\n",
        "  target = vars(data)[\"trg\"]\n",
        "\n",
        "  pred = convert(Model, source, SRC, TRG, device)\n",
        "\n",
        "  Target.append([target])\n",
        "  Output.append(pred)\n",
        "\n",
        "print(Target)\n",
        "print(Output)\n",
        "\n",
        "print(\"MODEL'S BLEU SCORE: \", bleu_score(Output, Target))"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[['y', 'r']], [['y', 'o', 'g']], [['i', 'v', 'r', 's']], [['n', 'q', 'f', 'l', 'v']], [['o', 't', 'p', 'g', 'o', 'b']], [['t', 'n', 'j', 'r', 'u', 'k', 'e']], [['w', 'p', 'q', 'h', 'j', 'u', 'o', 'w']], [['p', 'y', 'm', 'o', 'i', 'i', 'c', 'r', 'k']], [['h', 'v', 'j', 'w', 'z', 't', 'c', 'g', 'g', 'g']], [['d', 'd', 't', 'b', 'c', 'u', 'e', 'h', 'b', 'c', 'd']], [['s', 'e', 'w', 'p', 'a', 't', 't', 'o', 'l', 'n', 'y', 'z']], [['q', 'q', 'h', 'u', 'h', 'd', 'f', 'z', 't', 'c', 'e', 'i', 'a']], [['t', 'r', 'a', 'n', 'd', 'e', 'l', 'u', 'w', 'e', 'q', 'x', 'p', 'l']], [['o', 'c', 'l', 't', 'q', 'k', 'i', 'c', 'n', 'q', 'd', 'v', 'u', 'w', 'j']], [['e', 'q', 'o', 'd', 'd', 't', 'p', 'u', 'e', 'i', 'm', 'i', 's', 'j', 'e', 'y']], [['q', 'j', 'i', 'p', 'o', 'z', 't', 'p', 't', 'q', 'l', 'y', 'c', 'k', 'z', 'a', 't']], [['q', 'k', 'x', 'j', 'w', 'j', 't', 'x', 's', 'g', 'c', 'k', 'q', 'q', 'w', 'o', 'o', 'z']], [['n', 'w', 'd', 'z', 'z', 'e', 'e', 'j', 'y', 'b', 'm', 'e', 'm', 'm', 'v', 'm', 'p', 'r', 'i']], [['c', 'p', 'k', 'r', 'o', 'd', 'l', 'o', 'c', 'g', 'j', 'c', 'q', 'v', 'r', 'l', 'r', 'f', 'm', 'd']], [['a', 's', 'x', 'k', 'l', 'l', 's', 'f', 'x', 't', 'm', 'p', 'u', 'b', 'g', 'n', 't', 'g', 'u', 'y', 'b']]]\n",
            "[['y', 'r'], ['y', 'o', 'g'], ['i', 'v', 'r', 's'], ['n', 'q', 'f', 'l', 'v'], ['o', 't', 'p', 'g', 'b', '<eos>'], ['t', 'n', 'j', 'r', 'u', 'k', 'e'], ['w', 'p', 'q', 'h', 'j', 'u', 'o', 'w'], ['p', 'y', 'm', 'o', 'i', 'c', 'r', 'k', '<eos>'], ['h', 'v', 'j', 'w', 'z', 't', 'c', 'g', 'g', '<eos>'], ['d', 't', 'b', 'c', 'u', 'e', 'h', 'c', 'd', 'b', '<eos>'], ['s', 'e', 'w', 'p', 'a', 't', 'o', 'l', 'n', 'y', 'z', '<eos>'], ['q', 'h', 'u', 'd', 'f', 'h', 'z', 't', 'c', 'c', 'e', 'i', 'a'], ['t', 'r', 'a', 'n', 'd', 'e', 'e', 'u', 'l', 'w', 'e', 'x', 'p', 'l'], ['o', 'c', 'l', 't', 'q', 'k', 'i', 'q', 'n', 'd', 'v', 'u', 'j', 'w', '<eos>'], ['e', 'q', 'd', 't', 'o', 'p', 'u', 'i', 'i', 'm', 'e', 's', 'j', 'y', 'y', '<eos>'], ['q', 'j', 'i', 'o', 'p', 'p', 't', 'z', 't', 'y', 'c', 'k', 'z', 'a', 'a', 't', '<eos>'], ['q', 'k', 'x', 'j', 'w', 'j', 'x', 'c', 'k', 'g', 'q', 'w', 'q', 'o', 'o', 'z', '<eos>', '<eos>'], ['n', 'd', 'z', 'w', 'e', 'e', 'j', 'b', 'm', 'm', 'm', 'm', 'r', 'p', 'i', '<eos>', '<eos>', '<eos>', '<eos>'], ['c', 'p', 'k', 'o', 'r', 'd', 'l', 'l', 'l', 'l', 'v', 'v', 'g', 'r', 'r', 'f', 'm', 'd', '<eos>', '<eos>'], ['a', 's', 'x', 'l', 'k', 'f', 'f', 'x', 'p', 'u', 'm', 't', 'b', 'g', 'g', 'n', 'u', 'b', 'y', '<eos>', '<eos>']]\n",
            "MODEL'S BLEU SCORE:  0.48137080669403076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAChojF1Ody6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}